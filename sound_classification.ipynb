{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.87 ms, sys: 23.5 ms, total: 27.3 ms\n",
      "Wall time: 29.6 ms\n",
      "loaded successfully. # of train data=6269, # of test data=2459\n"
     ]
    }
   ],
   "source": [
    "# データ読み込み\n",
    "import urbansound8k_loader as dataset\n",
    "\n",
    "#parent_dir = 'UrbanSound8K/audio/'\n",
    "#tr_features, tr_labels = dataset.load_urbansound8k(parent_dir, ['fold1', 'fold2'])\n",
    "#ts_features, ts_labels = dataset.load_urbansound8k(parent_dir, ['fold3'])\n",
    "\n",
    "%time tr_features, tr_labels, ts_features, ts_labels = dataset.load_from_npy_files('all_')\n",
    "\n",
    "if (len(tr_features) !=  len(tr_labels)):\n",
    "    print('WARN: invalid # of training data. features=' + str(len(tr_features)) + ', labels=' + str(len(tr_labels)))\n",
    "elif (len(ts_features) !=  len(ts_labels)):\n",
    "    print('WARN: invalid # of tast data. features=' + str(len(ts_features)) + ', labels=' + str(len(ts_labels)))\n",
    "elif (len(tr_features) == 0 or len(ts_features) == 0):\n",
    "    print('WARN: no data.')\n",
    "else: \n",
    "    print('loaded successfully. # of train data=' + str(len(tr_features)) + ', # of test data=' + str(len(ts_features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 5000\n",
    "n_dim = tr_features.shape[1]  # 193\n",
    "n_classes = 10\n",
    "n_hidden_units_one = 280 \n",
    "n_hidden_units_two = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 280)               54320     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 280)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               84300     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 141,630\n",
      "Trainable params: 141,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fit start:  2017/07/04 02:17:09\n",
      "Train on 6269 samples, validate on 2459 samples\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0 is illegal; using dense_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0 is illegal; using dense_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_3/kernel:0 is illegal; using dense_3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_3/bias:0 is illegal; using dense_3/bias_0 instead.\n",
      "Epoch 1/5000\n",
      "6269/6269 [==============================] - 1s - loss: 8.3235 - acc: 0.3056 - val_loss: 6.6870 - val_acc: 0.3241\n",
      "Epoch 2/5000\n",
      "6269/6269 [==============================] - 1s - loss: 3.0976 - acc: 0.4494 - val_loss: 2.7026 - val_acc: 0.3810\n",
      "Epoch 3/5000\n",
      "6269/6269 [==============================] - 1s - loss: 1.7176 - acc: 0.5400 - val_loss: 2.4584 - val_acc: 0.4290\n",
      "Epoch 4/5000\n",
      "6269/6269 [==============================] - 1s - loss: 1.3581 - acc: 0.6247 - val_loss: 2.2875 - val_acc: 0.4669\n",
      "Epoch 5/5000\n",
      "6269/6269 [==============================] - 1s - loss: 1.1426 - acc: 0.6846 - val_loss: 2.2272 - val_acc: 0.4880\n",
      "Epoch 6/5000\n",
      "6269/6269 [==============================] - 1s - loss: 1.0056 - acc: 0.7319 - val_loss: 2.2609 - val_acc: 0.4815\n",
      "Epoch 7/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.8600 - acc: 0.7754 - val_loss: 2.3801 - val_acc: 0.4994\n",
      "Epoch 8/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.7901 - acc: 0.7893 - val_loss: 2.4773 - val_acc: 0.5140\n",
      "Epoch 9/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.7146 - acc: 0.8174 - val_loss: 2.4265 - val_acc: 0.5100\n",
      "Epoch 10/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.6528 - acc: 0.8312 - val_loss: 2.4514 - val_acc: 0.4998\n",
      "Epoch 11/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.5986 - acc: 0.8553 - val_loss: 2.5127 - val_acc: 0.5022\n",
      "Epoch 12/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.5838 - acc: 0.8639 - val_loss: 2.5204 - val_acc: 0.5242\n",
      "Epoch 13/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.5278 - acc: 0.8741 - val_loss: 2.6186 - val_acc: 0.5189\n",
      "Epoch 14/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.5112 - acc: 0.8808 - val_loss: 2.8136 - val_acc: 0.5128\n",
      "Epoch 15/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.5044 - acc: 0.8859 - val_loss: 2.7431 - val_acc: 0.5433\n",
      "Epoch 16/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.4486 - acc: 0.8963 - val_loss: 2.7839 - val_acc: 0.5234\n",
      "Epoch 17/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.4488 - acc: 0.9048 - val_loss: 2.9439 - val_acc: 0.5344\n",
      "Epoch 18/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.4182 - acc: 0.9088 - val_loss: 2.8338 - val_acc: 0.5185\n",
      "Epoch 19/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.4131 - acc: 0.9041 - val_loss: 2.9320 - val_acc: 0.5234\n",
      "Epoch 20/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3889 - acc: 0.9131 - val_loss: 3.0088 - val_acc: 0.5136\n",
      "Epoch 21/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3872 - acc: 0.9174 - val_loss: 3.0683 - val_acc: 0.5266\n",
      "Epoch 22/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3575 - acc: 0.9253 - val_loss: 3.2242 - val_acc: 0.5356\n",
      "Epoch 23/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3382 - acc: 0.9260 - val_loss: 3.1340 - val_acc: 0.5319\n",
      "Epoch 24/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3381 - acc: 0.9324 - val_loss: 3.1883 - val_acc: 0.5523\n",
      "Epoch 25/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3245 - acc: 0.9357 - val_loss: 3.3937 - val_acc: 0.5413\n",
      "Epoch 26/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3290 - acc: 0.9338 - val_loss: 3.3031 - val_acc: 0.5482\n",
      "Epoch 27/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3177 - acc: 0.9387 - val_loss: 3.4273 - val_acc: 0.5519\n",
      "Epoch 28/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3321 - acc: 0.9381 - val_loss: 3.4906 - val_acc: 0.5425\n",
      "Epoch 29/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3180 - acc: 0.9405 - val_loss: 3.3293 - val_acc: 0.5498\n",
      "Epoch 30/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3171 - acc: 0.9423 - val_loss: 3.6608 - val_acc: 0.5417\n",
      "Epoch 31/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3184 - acc: 0.9411 - val_loss: 3.6913 - val_acc: 0.5433\n",
      "Epoch 32/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2895 - acc: 0.9483 - val_loss: 3.5575 - val_acc: 0.5417\n",
      "Epoch 33/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3013 - acc: 0.9442 - val_loss: 3.4616 - val_acc: 0.5551\n",
      "Epoch 34/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.3056 - acc: 0.9461 - val_loss: 3.6868 - val_acc: 0.5449\n",
      "Epoch 35/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2997 - acc: 0.9493 - val_loss: 3.9243 - val_acc: 0.5368\n",
      "Epoch 36/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2858 - acc: 0.9509 - val_loss: 3.6859 - val_acc: 0.5466\n",
      "Epoch 37/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2906 - acc: 0.9499 - val_loss: 3.7402 - val_acc: 0.5527\n",
      "Epoch 38/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2816 - acc: 0.9518 - val_loss: 3.7569 - val_acc: 0.5323\n",
      "Epoch 39/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2777 - acc: 0.9550 - val_loss: 3.7938 - val_acc: 0.5437\n",
      "Epoch 40/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2494 - acc: 0.9588 - val_loss: 4.1498 - val_acc: 0.5336\n",
      "Epoch 41/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2531 - acc: 0.9603 - val_loss: 3.7934 - val_acc: 0.5543\n",
      "Epoch 42/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2340 - acc: 0.9614 - val_loss: 3.8573 - val_acc: 0.5368\n",
      "Epoch 43/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2471 - acc: 0.9592 - val_loss: 3.9517 - val_acc: 0.5551\n",
      "Epoch 44/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2187 - acc: 0.9616 - val_loss: 4.0940 - val_acc: 0.5445\n",
      "Epoch 45/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2150 - acc: 0.9585 - val_loss: 4.0860 - val_acc: 0.5494\n",
      "Epoch 46/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.2153 - acc: 0.9625 - val_loss: 3.9840 - val_acc: 0.5417\n",
      "Epoch 47/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1957 - acc: 0.9638 - val_loss: 3.9978 - val_acc: 0.5539\n",
      "Epoch 48/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1816 - acc: 0.9630 - val_loss: 4.1870 - val_acc: 0.5242\n",
      "Epoch 49/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1952 - acc: 0.9633 - val_loss: 3.9908 - val_acc: 0.5555\n",
      "Epoch 50/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1922 - acc: 0.9646 - val_loss: 4.0624 - val_acc: 0.5453\n",
      "Epoch 51/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1929 - acc: 0.9625 - val_loss: 4.1571 - val_acc: 0.5380\n",
      "Epoch 52/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6269/6269 [==============================] - 1s - loss: 0.1632 - acc: 0.9689 - val_loss: 3.9235 - val_acc: 0.5482\n",
      "Epoch 53/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1756 - acc: 0.9654 - val_loss: 4.0022 - val_acc: 0.5519\n",
      "Epoch 54/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1589 - acc: 0.9681 - val_loss: 3.9625 - val_acc: 0.5584\n",
      "Epoch 55/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1701 - acc: 0.9679 - val_loss: 4.0308 - val_acc: 0.5478\n",
      "Epoch 56/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1686 - acc: 0.9679 - val_loss: 4.0691 - val_acc: 0.5588\n",
      "Epoch 57/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1587 - acc: 0.9727 - val_loss: 4.0486 - val_acc: 0.5575\n",
      "Epoch 58/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1609 - acc: 0.9681 - val_loss: 4.3812 - val_acc: 0.5258\n",
      "Epoch 59/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1567 - acc: 0.9713 - val_loss: 4.2385 - val_acc: 0.5437\n",
      "Epoch 60/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1769 - acc: 0.9691 - val_loss: 4.3063 - val_acc: 0.5433\n",
      "Epoch 61/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1653 - acc: 0.9684 - val_loss: 4.1907 - val_acc: 0.5433\n",
      "Epoch 62/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1698 - acc: 0.9703 - val_loss: 4.3781 - val_acc: 0.5425\n",
      "Epoch 63/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1458 - acc: 0.9705 - val_loss: 4.1013 - val_acc: 0.5571\n",
      "Epoch 64/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1495 - acc: 0.9729 - val_loss: 4.2257 - val_acc: 0.5490\n",
      "Epoch 65/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1607 - acc: 0.9729 - val_loss: 4.0918 - val_acc: 0.5584\n",
      "Epoch 66/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1672 - acc: 0.9735 - val_loss: 4.4710 - val_acc: 0.5405\n",
      "Epoch 67/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1761 - acc: 0.9706 - val_loss: 4.4051 - val_acc: 0.5307\n",
      "Epoch 68/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1757 - acc: 0.9706 - val_loss: 4.4170 - val_acc: 0.5331\n",
      "Epoch 69/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1725 - acc: 0.9721 - val_loss: 4.4290 - val_acc: 0.5466\n",
      "Epoch 70/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1786 - acc: 0.9722 - val_loss: 4.4389 - val_acc: 0.5405\n",
      "Epoch 71/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1503 - acc: 0.9705 - val_loss: 4.2744 - val_acc: 0.5490\n",
      "Epoch 72/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1459 - acc: 0.9740 - val_loss: 4.2003 - val_acc: 0.5620\n",
      "Epoch 73/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1484 - acc: 0.9745 - val_loss: 4.2504 - val_acc: 0.5608\n",
      "Epoch 74/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1372 - acc: 0.9750 - val_loss: 4.2663 - val_acc: 0.5299\n",
      "Epoch 75/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1580 - acc: 0.9726 - val_loss: 4.2693 - val_acc: 0.5510\n",
      "Epoch 76/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1348 - acc: 0.9750 - val_loss: 4.3539 - val_acc: 0.5535\n",
      "Epoch 77/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1313 - acc: 0.9769 - val_loss: 4.5751 - val_acc: 0.5514\n",
      "Epoch 78/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1301 - acc: 0.9777 - val_loss: 4.4301 - val_acc: 0.5441\n",
      "Epoch 79/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1544 - acc: 0.9761 - val_loss: 4.4849 - val_acc: 0.5510\n",
      "Epoch 80/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1499 - acc: 0.9734 - val_loss: 4.2704 - val_acc: 0.5600\n",
      "Epoch 81/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1434 - acc: 0.9764 - val_loss: 4.7905 - val_acc: 0.5368\n",
      "Epoch 82/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1478 - acc: 0.9746 - val_loss: 4.7394 - val_acc: 0.5437\n",
      "Epoch 83/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1403 - acc: 0.9754 - val_loss: 4.5318 - val_acc: 0.5510\n",
      "Epoch 84/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1386 - acc: 0.9767 - val_loss: 4.5461 - val_acc: 0.5384\n",
      "Epoch 85/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1497 - acc: 0.9746 - val_loss: 4.6968 - val_acc: 0.5523\n",
      "Epoch 86/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1452 - acc: 0.9756 - val_loss: 4.5336 - val_acc: 0.5494\n",
      "Epoch 87/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1605 - acc: 0.9743 - val_loss: 4.5639 - val_acc: 0.5506\n",
      "Epoch 88/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1248 - acc: 0.9781 - val_loss: 4.6862 - val_acc: 0.5384\n",
      "Epoch 89/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1323 - acc: 0.9785 - val_loss: 4.5742 - val_acc: 0.5466\n",
      "Epoch 90/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1485 - acc: 0.9762 - val_loss: 4.6142 - val_acc: 0.5706\n",
      "Epoch 91/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1373 - acc: 0.9764 - val_loss: 4.5417 - val_acc: 0.5612\n",
      "Epoch 92/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1440 - acc: 0.9767 - val_loss: 4.5046 - val_acc: 0.5490\n",
      "Epoch 93/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1284 - acc: 0.9780 - val_loss: 4.6090 - val_acc: 0.5514\n",
      "Epoch 94/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1524 - acc: 0.9759 - val_loss: 4.6032 - val_acc: 0.5535\n",
      "Epoch 95/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1492 - acc: 0.9756 - val_loss: 4.5141 - val_acc: 0.5596\n",
      "Epoch 96/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1326 - acc: 0.9775 - val_loss: 4.5708 - val_acc: 0.5425\n",
      "Epoch 97/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1443 - acc: 0.9758 - val_loss: 4.6500 - val_acc: 0.5527\n",
      "Epoch 98/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1367 - acc: 0.9789 - val_loss: 4.8161 - val_acc: 0.5429\n",
      "Epoch 99/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1360 - acc: 0.9754 - val_loss: 4.5638 - val_acc: 0.5653\n",
      "Epoch 100/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1262 - acc: 0.9785 - val_loss: 4.8252 - val_acc: 0.5571\n",
      "Epoch 101/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1422 - acc: 0.9769 - val_loss: 4.6501 - val_acc: 0.5470\n",
      "Epoch 102/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1411 - acc: 0.9793 - val_loss: 4.5777 - val_acc: 0.5519\n",
      "Epoch 103/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1697 - acc: 0.9745 - val_loss: 4.7427 - val_acc: 0.5580\n",
      "Epoch 104/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1433 - acc: 0.9767 - val_loss: 4.6643 - val_acc: 0.5364\n",
      "Epoch 105/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1212 - acc: 0.9833 - val_loss: 4.7252 - val_acc: 0.5588\n",
      "Epoch 106/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1342 - acc: 0.9789 - val_loss: 4.6198 - val_acc: 0.5604\n",
      "Epoch 107/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1355 - acc: 0.9772 - val_loss: 4.5755 - val_acc: 0.5596\n",
      "Epoch 108/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1434 - acc: 0.9791 - val_loss: 4.7106 - val_acc: 0.5677\n",
      "Epoch 109/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1211 - acc: 0.9821 - val_loss: 4.8939 - val_acc: 0.5433\n",
      "Epoch 110/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1453 - acc: 0.9767 - val_loss: 4.7306 - val_acc: 0.5519\n",
      "Epoch 111/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1384 - acc: 0.9793 - val_loss: 4.9309 - val_acc: 0.5502\n",
      "Epoch 112/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1495 - acc: 0.9786 - val_loss: 4.9525 - val_acc: 0.5425\n",
      "Epoch 113/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1492 - acc: 0.9793 - val_loss: 4.7624 - val_acc: 0.5571\n",
      "Epoch 114/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1579 - acc: 0.9775 - val_loss: 4.7656 - val_acc: 0.5791\n",
      "Epoch 115/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6269/6269 [==============================] - 1s - loss: 0.1219 - acc: 0.9799 - val_loss: 4.8554 - val_acc: 0.5734\n",
      "Epoch 116/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1384 - acc: 0.9789 - val_loss: 4.9078 - val_acc: 0.5539\n",
      "Epoch 117/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1382 - acc: 0.9802 - val_loss: 4.7784 - val_acc: 0.5620\n",
      "Epoch 118/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1300 - acc: 0.9783 - val_loss: 4.8472 - val_acc: 0.5608\n",
      "Epoch 119/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1379 - acc: 0.9785 - val_loss: 4.6806 - val_acc: 0.5539\n",
      "Epoch 120/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1371 - acc: 0.9778 - val_loss: 4.6677 - val_acc: 0.5539\n",
      "Epoch 121/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1553 - acc: 0.9796 - val_loss: 5.0353 - val_acc: 0.5559\n",
      "Epoch 122/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1438 - acc: 0.9793 - val_loss: 4.9833 - val_acc: 0.5490\n",
      "Epoch 123/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1161 - acc: 0.9810 - val_loss: 4.9568 - val_acc: 0.5726\n",
      "Epoch 124/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1439 - acc: 0.9793 - val_loss: 4.8674 - val_acc: 0.5506\n",
      "Epoch 125/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1373 - acc: 0.9793 - val_loss: 5.1665 - val_acc: 0.5425\n",
      "Epoch 126/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1396 - acc: 0.9764 - val_loss: 5.0535 - val_acc: 0.5502\n",
      "Epoch 127/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1372 - acc: 0.9797 - val_loss: 4.8817 - val_acc: 0.5600\n",
      "Epoch 128/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1320 - acc: 0.9815 - val_loss: 5.0145 - val_acc: 0.5490\n",
      "Epoch 129/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1684 - acc: 0.9770 - val_loss: 4.7481 - val_acc: 0.5653\n",
      "Epoch 130/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1363 - acc: 0.9829 - val_loss: 4.9359 - val_acc: 0.5563\n",
      "Epoch 131/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1567 - acc: 0.9793 - val_loss: 4.8397 - val_acc: 0.5588\n",
      "Epoch 132/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1420 - acc: 0.9804 - val_loss: 4.8989 - val_acc: 0.5636\n",
      "Epoch 133/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1386 - acc: 0.9781 - val_loss: 4.8658 - val_acc: 0.5795\n",
      "Epoch 134/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1506 - acc: 0.9773 - val_loss: 5.0439 - val_acc: 0.5409\n",
      "Epoch 135/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1388 - acc: 0.9786 - val_loss: 5.1471 - val_acc: 0.5360\n",
      "Epoch 136/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1496 - acc: 0.9781 - val_loss: 4.8721 - val_acc: 0.5645\n",
      "Epoch 137/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1296 - acc: 0.9825 - val_loss: 5.0331 - val_acc: 0.5592\n",
      "Epoch 138/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1313 - acc: 0.9794 - val_loss: 4.9643 - val_acc: 0.5592\n",
      "Epoch 139/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1238 - acc: 0.9821 - val_loss: 5.0601 - val_acc: 0.5462\n",
      "Epoch 140/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1367 - acc: 0.9791 - val_loss: 5.0331 - val_acc: 0.5486\n",
      "Epoch 141/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1372 - acc: 0.9802 - val_loss: 4.9966 - val_acc: 0.5673\n",
      "Epoch 142/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1371 - acc: 0.9805 - val_loss: 5.0990 - val_acc: 0.5636\n",
      "Epoch 143/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1297 - acc: 0.9818 - val_loss: 5.0209 - val_acc: 0.5632\n",
      "Epoch 144/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1286 - acc: 0.9812 - val_loss: 5.2719 - val_acc: 0.5612\n",
      "Epoch 145/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1275 - acc: 0.9807 - val_loss: 5.0278 - val_acc: 0.5592\n",
      "Epoch 146/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1406 - acc: 0.9788 - val_loss: 5.0395 - val_acc: 0.5596\n",
      "Epoch 147/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1475 - acc: 0.9791 - val_loss: 5.2758 - val_acc: 0.5417\n",
      "Epoch 148/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1486 - acc: 0.9807 - val_loss: 5.0920 - val_acc: 0.5449\n",
      "Epoch 149/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1345 - acc: 0.9805 - val_loss: 5.2258 - val_acc: 0.5498\n",
      "Epoch 150/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1398 - acc: 0.9789 - val_loss: 5.1461 - val_acc: 0.5600\n",
      "Epoch 151/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1455 - acc: 0.9791 - val_loss: 5.1193 - val_acc: 0.5433\n",
      "Epoch 152/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1484 - acc: 0.9802 - val_loss: 5.1993 - val_acc: 0.5502\n",
      "Epoch 153/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1263 - acc: 0.9820 - val_loss: 5.1287 - val_acc: 0.5555\n",
      "Epoch 154/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1438 - acc: 0.9793 - val_loss: 4.9757 - val_acc: 0.5616\n",
      "Epoch 155/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1409 - acc: 0.9815 - val_loss: 5.2994 - val_acc: 0.5458\n",
      "Epoch 156/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1343 - acc: 0.9821 - val_loss: 5.0235 - val_acc: 0.5592\n",
      "Epoch 157/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1293 - acc: 0.9809 - val_loss: 4.9168 - val_acc: 0.5624\n",
      "Epoch 158/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1175 - acc: 0.9839 - val_loss: 5.0446 - val_acc: 0.5600\n",
      "Epoch 159/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1278 - acc: 0.9793 - val_loss: 5.2567 - val_acc: 0.5486\n",
      "Epoch 160/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1209 - acc: 0.9826 - val_loss: 5.2574 - val_acc: 0.5458\n",
      "Epoch 161/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1409 - acc: 0.9801 - val_loss: 5.2859 - val_acc: 0.5592\n",
      "Epoch 162/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1279 - acc: 0.9812 - val_loss: 5.3197 - val_acc: 0.5596\n",
      "Epoch 163/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1072 - acc: 0.9823 - val_loss: 5.2498 - val_acc: 0.5474\n",
      "Epoch 164/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1335 - acc: 0.9805 - val_loss: 5.1306 - val_acc: 0.5514\n",
      "Epoch 165/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1438 - acc: 0.9807 - val_loss: 5.2232 - val_acc: 0.5445\n",
      "Epoch 166/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1388 - acc: 0.9796 - val_loss: 5.1185 - val_acc: 0.5584\n",
      "Epoch 167/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1322 - acc: 0.9815 - val_loss: 4.9580 - val_acc: 0.5584\n",
      "Epoch 168/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1262 - acc: 0.9825 - val_loss: 5.2379 - val_acc: 0.5608\n",
      "Epoch 169/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1614 - acc: 0.9794 - val_loss: 5.2756 - val_acc: 0.5669\n",
      "Epoch 170/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1495 - acc: 0.9796 - val_loss: 5.1048 - val_acc: 0.5706\n",
      "Epoch 171/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1173 - acc: 0.9833 - val_loss: 5.3052 - val_acc: 0.5470\n",
      "Epoch 172/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1351 - acc: 0.9818 - val_loss: 5.1922 - val_acc: 0.5600\n",
      "Epoch 173/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1291 - acc: 0.9807 - val_loss: 5.3328 - val_acc: 0.5494\n",
      "Epoch 174/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1396 - acc: 0.9826 - val_loss: 5.1795 - val_acc: 0.5539\n",
      "Epoch 175/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1298 - acc: 0.9826 - val_loss: 5.1671 - val_acc: 0.5523\n",
      "Epoch 176/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1359 - acc: 0.9818 - val_loss: 5.1470 - val_acc: 0.5600\n",
      "Epoch 177/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1462 - acc: 0.9807 - val_loss: 5.2166 - val_acc: 0.5514\n",
      "Epoch 178/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6269/6269 [==============================] - 1s - loss: 0.1458 - acc: 0.9801 - val_loss: 5.4164 - val_acc: 0.5380\n",
      "Epoch 179/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1195 - acc: 0.9813 - val_loss: 5.4836 - val_acc: 0.5490\n",
      "Epoch 180/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1239 - acc: 0.9818 - val_loss: 5.2761 - val_acc: 0.5417\n",
      "Epoch 181/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1243 - acc: 0.9815 - val_loss: 5.2892 - val_acc: 0.5486\n",
      "Epoch 182/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1301 - acc: 0.9821 - val_loss: 5.2174 - val_acc: 0.5584\n",
      "Epoch 183/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1474 - acc: 0.9807 - val_loss: 4.9768 - val_acc: 0.5584\n",
      "Epoch 184/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1587 - acc: 0.9794 - val_loss: 5.0583 - val_acc: 0.5681\n",
      "Epoch 185/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1263 - acc: 0.9828 - val_loss: 5.1681 - val_acc: 0.5486\n",
      "Epoch 186/5000\n",
      "6269/6269 [==============================] - 6s - loss: 0.1395 - acc: 0.9801 - val_loss: 5.3410 - val_acc: 0.5417\n",
      "Epoch 187/5000\n",
      "6269/6269 [==============================] - 2s - loss: 0.1262 - acc: 0.9818 - val_loss: 5.1283 - val_acc: 0.5608\n",
      "Epoch 188/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1343 - acc: 0.9801 - val_loss: 5.2152 - val_acc: 0.5596\n",
      "Epoch 189/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1419 - acc: 0.9828 - val_loss: 5.1173 - val_acc: 0.5563\n",
      "Epoch 190/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1531 - acc: 0.9773 - val_loss: 5.0368 - val_acc: 0.5620\n",
      "Epoch 191/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1364 - acc: 0.9794 - val_loss: 5.1774 - val_acc: 0.5466\n",
      "Epoch 192/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1403 - acc: 0.9820 - val_loss: 5.1275 - val_acc: 0.5559\n",
      "Epoch 193/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1314 - acc: 0.9805 - val_loss: 5.1981 - val_acc: 0.5571\n",
      "Epoch 194/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1140 - acc: 0.9864 - val_loss: 5.1839 - val_acc: 0.5628\n",
      "Epoch 195/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1298 - acc: 0.9834 - val_loss: 5.3115 - val_acc: 0.5514\n",
      "Epoch 196/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1424 - acc: 0.9789 - val_loss: 5.2018 - val_acc: 0.5604\n",
      "Epoch 197/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1140 - acc: 0.9850 - val_loss: 5.2264 - val_acc: 0.5722\n",
      "Epoch 198/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1300 - acc: 0.9823 - val_loss: 5.3110 - val_acc: 0.5571\n",
      "Epoch 199/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1335 - acc: 0.9820 - val_loss: 5.2802 - val_acc: 0.5649\n",
      "Epoch 200/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1339 - acc: 0.9815 - val_loss: 5.3063 - val_acc: 0.5519\n",
      "Epoch 201/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1279 - acc: 0.9825 - val_loss: 5.2219 - val_acc: 0.5677\n",
      "Epoch 202/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1330 - acc: 0.9802 - val_loss: 5.2641 - val_acc: 0.5580\n",
      "Epoch 203/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1666 - acc: 0.9788 - val_loss: 5.3768 - val_acc: 0.5498\n",
      "Epoch 204/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1380 - acc: 0.9817 - val_loss: 5.2495 - val_acc: 0.5604\n",
      "Epoch 205/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1378 - acc: 0.9837 - val_loss: 5.3716 - val_acc: 0.5510\n",
      "Epoch 206/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1461 - acc: 0.9807 - val_loss: 5.1044 - val_acc: 0.5702\n",
      "Epoch 207/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1392 - acc: 0.9807 - val_loss: 5.2184 - val_acc: 0.5608\n",
      "Epoch 208/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1391 - acc: 0.9826 - val_loss: 5.1062 - val_acc: 0.5673\n",
      "Epoch 209/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1348 - acc: 0.9818 - val_loss: 5.0640 - val_acc: 0.5624\n",
      "Epoch 210/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1380 - acc: 0.9815 - val_loss: 5.3142 - val_acc: 0.5506\n",
      "Epoch 211/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1496 - acc: 0.9807 - val_loss: 5.1734 - val_acc: 0.5559\n",
      "Epoch 212/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1242 - acc: 0.9815 - val_loss: 5.3765 - val_acc: 0.5563\n",
      "Epoch 213/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1147 - acc: 0.9844 - val_loss: 5.3766 - val_acc: 0.5466\n",
      "Epoch 214/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1406 - acc: 0.9813 - val_loss: 5.2903 - val_acc: 0.5441\n",
      "Epoch 215/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1208 - acc: 0.9845 - val_loss: 5.2833 - val_acc: 0.5645\n",
      "Epoch 216/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1436 - acc: 0.9810 - val_loss: 5.0962 - val_acc: 0.5592\n",
      "Epoch 217/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1435 - acc: 0.9826 - val_loss: 5.0514 - val_acc: 0.5763\n",
      "Epoch 218/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1342 - acc: 0.9823 - val_loss: 5.1394 - val_acc: 0.5681\n",
      "Epoch 219/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1278 - acc: 0.9818 - val_loss: 5.1872 - val_acc: 0.5580\n",
      "Epoch 220/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1261 - acc: 0.9834 - val_loss: 5.4047 - val_acc: 0.5669\n",
      "Epoch 221/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1213 - acc: 0.9829 - val_loss: 5.2862 - val_acc: 0.5612\n",
      "Epoch 222/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1229 - acc: 0.9837 - val_loss: 5.3605 - val_acc: 0.5649\n",
      "Epoch 223/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1297 - acc: 0.9809 - val_loss: 5.2036 - val_acc: 0.5636\n",
      "Epoch 224/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1276 - acc: 0.9836 - val_loss: 5.1748 - val_acc: 0.5661\n",
      "Epoch 225/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1249 - acc: 0.9836 - val_loss: 5.3961 - val_acc: 0.5519\n",
      "Epoch 226/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1234 - acc: 0.9828 - val_loss: 5.3640 - val_acc: 0.5474\n",
      "Epoch 227/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1093 - acc: 0.9855 - val_loss: 5.3197 - val_acc: 0.5519\n",
      "Epoch 228/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1302 - acc: 0.9802 - val_loss: 5.5055 - val_acc: 0.5474\n",
      "Epoch 229/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1475 - acc: 0.9813 - val_loss: 5.5033 - val_acc: 0.5445\n",
      "Epoch 230/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1588 - acc: 0.9807 - val_loss: 5.4117 - val_acc: 0.5571\n",
      "Epoch 231/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1434 - acc: 0.9815 - val_loss: 5.3560 - val_acc: 0.5502\n",
      "Epoch 232/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1320 - acc: 0.9831 - val_loss: 5.3375 - val_acc: 0.5628\n",
      "Epoch 233/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1435 - acc: 0.9821 - val_loss: 5.3892 - val_acc: 0.5681\n",
      "Epoch 234/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1660 - acc: 0.9797 - val_loss: 5.4904 - val_acc: 0.5510\n",
      "Epoch 235/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1465 - acc: 0.9815 - val_loss: 5.2853 - val_acc: 0.5425\n",
      "Epoch 236/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1291 - acc: 0.9813 - val_loss: 5.3762 - val_acc: 0.5547\n",
      "Epoch 237/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1342 - acc: 0.9833 - val_loss: 5.4654 - val_acc: 0.5498\n",
      "Epoch 238/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1461 - acc: 0.9785 - val_loss: 5.3850 - val_acc: 0.5486\n",
      "Epoch 239/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1302 - acc: 0.9826 - val_loss: 5.4578 - val_acc: 0.5575\n",
      "Epoch 240/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1415 - acc: 0.9813 - val_loss: 5.4707 - val_acc: 0.5490\n",
      "Epoch 241/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6269/6269 [==============================] - 1s - loss: 0.1380 - acc: 0.9825 - val_loss: 5.2505 - val_acc: 0.5702\n",
      "Epoch 242/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1367 - acc: 0.9833 - val_loss: 5.4436 - val_acc: 0.5641\n",
      "Epoch 243/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1455 - acc: 0.9823 - val_loss: 5.4020 - val_acc: 0.5657\n",
      "Epoch 244/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1454 - acc: 0.9812 - val_loss: 5.3195 - val_acc: 0.5514\n",
      "Epoch 245/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1563 - acc: 0.9817 - val_loss: 5.3610 - val_acc: 0.5714\n",
      "Epoch 246/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1404 - acc: 0.9829 - val_loss: 5.4263 - val_acc: 0.5462\n",
      "Epoch 247/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1212 - acc: 0.9844 - val_loss: 5.5010 - val_acc: 0.5409\n",
      "Epoch 248/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1235 - acc: 0.9836 - val_loss: 5.5882 - val_acc: 0.5474\n",
      "Epoch 249/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1193 - acc: 0.9818 - val_loss: 5.3887 - val_acc: 0.5539\n",
      "Epoch 250/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1300 - acc: 0.9821 - val_loss: 5.4428 - val_acc: 0.5580\n",
      "Epoch 251/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1275 - acc: 0.9833 - val_loss: 5.5978 - val_acc: 0.5494\n",
      "Epoch 252/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1372 - acc: 0.9831 - val_loss: 5.4266 - val_acc: 0.5531\n",
      "Epoch 253/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1474 - acc: 0.9820 - val_loss: 5.2984 - val_acc: 0.5604\n",
      "Epoch 254/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1289 - acc: 0.9828 - val_loss: 5.5389 - val_acc: 0.5445\n",
      "Epoch 255/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1379 - acc: 0.9831 - val_loss: 5.4367 - val_acc: 0.5559\n",
      "Epoch 256/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1456 - acc: 0.9823 - val_loss: 5.3823 - val_acc: 0.5608\n",
      "Epoch 257/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1124 - acc: 0.9842 - val_loss: 5.4237 - val_acc: 0.5592\n",
      "Epoch 258/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1319 - acc: 0.9837 - val_loss: 5.3086 - val_acc: 0.5580\n",
      "Epoch 259/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1260 - acc: 0.9826 - val_loss: 5.5713 - val_acc: 0.5563\n",
      "Epoch 260/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1292 - acc: 0.9831 - val_loss: 5.3940 - val_acc: 0.5575\n",
      "Epoch 261/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1447 - acc: 0.9805 - val_loss: 5.6399 - val_acc: 0.5502\n",
      "Epoch 262/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1192 - acc: 0.9820 - val_loss: 5.4655 - val_acc: 0.5531\n",
      "Epoch 263/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1114 - acc: 0.9861 - val_loss: 5.3999 - val_acc: 0.5575\n",
      "Epoch 264/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1307 - acc: 0.9831 - val_loss: 5.4859 - val_acc: 0.5714\n",
      "Epoch 265/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1272 - acc: 0.9839 - val_loss: 5.6259 - val_acc: 0.5551\n",
      "Epoch 266/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1562 - acc: 0.9810 - val_loss: 5.3440 - val_acc: 0.5649\n",
      "Epoch 267/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1247 - acc: 0.9833 - val_loss: 5.4670 - val_acc: 0.5620\n",
      "Epoch 268/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1471 - acc: 0.9825 - val_loss: 5.5786 - val_acc: 0.5531\n",
      "Epoch 269/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1379 - acc: 0.9813 - val_loss: 5.4583 - val_acc: 0.5580\n",
      "Epoch 270/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1218 - acc: 0.9844 - val_loss: 5.4987 - val_acc: 0.5478\n",
      "Epoch 271/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1558 - acc: 0.9810 - val_loss: 5.3474 - val_acc: 0.5628\n",
      "Epoch 272/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1354 - acc: 0.9821 - val_loss: 5.5582 - val_acc: 0.5567\n",
      "Epoch 273/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1433 - acc: 0.9802 - val_loss: 5.6700 - val_acc: 0.5441\n",
      "Epoch 274/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1417 - acc: 0.9831 - val_loss: 5.4215 - val_acc: 0.5685\n",
      "Epoch 275/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1419 - acc: 0.9825 - val_loss: 5.5213 - val_acc: 0.5506\n",
      "Epoch 276/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1429 - acc: 0.9833 - val_loss: 5.4723 - val_acc: 0.5628\n",
      "Epoch 277/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1435 - acc: 0.9840 - val_loss: 5.3221 - val_acc: 0.5608\n",
      "Epoch 278/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1277 - acc: 0.9833 - val_loss: 5.6723 - val_acc: 0.5531\n",
      "Epoch 279/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1359 - acc: 0.9833 - val_loss: 5.5833 - val_acc: 0.5580\n",
      "Epoch 280/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1290 - acc: 0.9856 - val_loss: 5.5880 - val_acc: 0.5531\n",
      "Epoch 281/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1402 - acc: 0.9828 - val_loss: 5.5463 - val_acc: 0.5543\n",
      "Epoch 282/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1422 - acc: 0.9828 - val_loss: 5.5859 - val_acc: 0.5657\n",
      "Epoch 283/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1396 - acc: 0.9812 - val_loss: 5.4890 - val_acc: 0.5531\n",
      "Epoch 284/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1280 - acc: 0.9834 - val_loss: 5.3896 - val_acc: 0.5624\n",
      "Epoch 285/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1367 - acc: 0.9820 - val_loss: 5.5148 - val_acc: 0.5551\n",
      "Epoch 286/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1317 - acc: 0.9839 - val_loss: 5.2600 - val_acc: 0.5779\n",
      "Epoch 287/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1332 - acc: 0.9828 - val_loss: 5.5056 - val_acc: 0.5600\n",
      "Epoch 288/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1232 - acc: 0.9847 - val_loss: 5.4894 - val_acc: 0.5665\n",
      "Epoch 289/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1120 - acc: 0.9853 - val_loss: 5.6031 - val_acc: 0.5405\n",
      "Epoch 290/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1490 - acc: 0.9801 - val_loss: 5.3950 - val_acc: 0.5519\n",
      "Epoch 291/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1401 - acc: 0.9836 - val_loss: 5.3398 - val_acc: 0.5567\n",
      "Epoch 292/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1449 - acc: 0.9823 - val_loss: 5.4510 - val_acc: 0.5600\n",
      "Epoch 293/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1417 - acc: 0.9831 - val_loss: 5.5108 - val_acc: 0.5693\n",
      "Epoch 294/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1363 - acc: 0.9812 - val_loss: 5.4773 - val_acc: 0.5697\n",
      "Epoch 295/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1252 - acc: 0.9842 - val_loss: 5.5972 - val_acc: 0.5563\n",
      "Epoch 296/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1549 - acc: 0.9791 - val_loss: 5.3448 - val_acc: 0.5641\n",
      "Epoch 297/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1541 - acc: 0.9825 - val_loss: 5.6287 - val_acc: 0.5657\n",
      "Epoch 298/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1764 - acc: 0.9796 - val_loss: 5.4946 - val_acc: 0.5559\n",
      "Epoch 299/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1305 - acc: 0.9834 - val_loss: 5.3977 - val_acc: 0.5714\n",
      "Epoch 300/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1464 - acc: 0.9821 - val_loss: 5.4050 - val_acc: 0.5750\n",
      "Epoch 301/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1393 - acc: 0.9855 - val_loss: 5.6066 - val_acc: 0.5478\n",
      "Epoch 302/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1416 - acc: 0.9815 - val_loss: 5.6635 - val_acc: 0.5441\n",
      "Epoch 303/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1313 - acc: 0.9836 - val_loss: 5.5646 - val_acc: 0.5531\n",
      "Epoch 304/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6269/6269 [==============================] - 1s - loss: 0.1434 - acc: 0.9831 - val_loss: 5.7900 - val_acc: 0.5405\n",
      "Epoch 305/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1384 - acc: 0.9836 - val_loss: 5.6501 - val_acc: 0.5555\n",
      "Epoch 306/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1245 - acc: 0.9844 - val_loss: 5.4805 - val_acc: 0.5689\n",
      "Epoch 307/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1313 - acc: 0.9855 - val_loss: 5.4957 - val_acc: 0.5645\n",
      "Epoch 308/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1436 - acc: 0.9821 - val_loss: 5.3169 - val_acc: 0.5726\n",
      "Epoch 309/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1417 - acc: 0.9831 - val_loss: 5.5014 - val_acc: 0.5523\n",
      "Epoch 310/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1352 - acc: 0.9815 - val_loss: 5.6205 - val_acc: 0.5551\n",
      "Epoch 311/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1416 - acc: 0.9829 - val_loss: 5.3638 - val_acc: 0.5689\n",
      "Epoch 312/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1364 - acc: 0.9831 - val_loss: 5.6282 - val_acc: 0.5510\n",
      "Epoch 313/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1442 - acc: 0.9820 - val_loss: 5.4360 - val_acc: 0.5726\n",
      "Epoch 314/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1542 - acc: 0.9823 - val_loss: 5.4582 - val_acc: 0.5620\n",
      "Epoch 315/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1485 - acc: 0.9815 - val_loss: 5.4921 - val_acc: 0.5596\n",
      "Epoch 316/5000\n",
      "6269/6269 [==============================] - 1s - loss: 0.1351 - acc: 0.9836 - val_loss: 5.5041 - val_acc: 0.5498\n",
      "Epoch 317/5000\n",
      "4992/6269 [======================>.......] - ETA: 0s - loss: 0.1422 - acc: 0.9792"
     ]
    }
   ],
   "source": [
    "# モデル構築、学習、評価 by keras\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.callbacks\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "log_filepath = './keras/log'\n",
    "batch_size = 128\n",
    "old_session = KTF.get_session()\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    session = tf.Session('')\n",
    "    KTF.set_session(session)\n",
    "    KTF.set_learning_phase(1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_hidden_units_one, activation='relu', input_shape=(n_dim,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_hidden_units_two, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    tb_cb = keras.callbacks.TensorBoard(log_dir=log_filepath, histogram_freq=1)\n",
    "    cbks = [tb_cb]\n",
    "    \n",
    "    print ('fit start: ', datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "    history = model.fit(tr_features, tr_labels,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=training_epochs,\n",
    "                        verbose=1,\n",
    "                        callbacks=cbks, \n",
    "                        validation_data=(ts_features, ts_labels))\n",
    "\n",
    "    print ('evaluate start: ', datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "    score = model.evaluate(ts_features, ts_labels, verbose=0)\n",
    "    print('Test accuracy:', score[1])\n",
    "    print ('finished: ', datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "\n",
    "KTF.set_session(old_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
